{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to Lambda Forge, a cutting-edge framework designed to redefine the deployment and management of AWS Lambda functions. Lambda Forge stands at the intersection of innovation and functionality, offering a seamless pipeline for transitioning code from retrieval to production \ud83d\ude80.</p> <p>Lambda Forge is not just about deployment; it's about creating a harmonious environment for your Lambda functions. With an emphasis on a consistent directory structure, it sets the stage for effortless management, deployment, and scalability. Through the synergistic use of AWS CloudFormation stack and AWS CDK, the framework orchestrates the build, test, and deployment processes, efficiently managing code from GitHub repositories across various environments.</p> <p>One of the hallmark features of Lambda Forge is its dedication to best practices in code organization, testing, and integration. It champions the cause of high-quality, maintainable code standards \ud83d\udcda. The introduction of the Forge command-line interface tool is a game-changer, simplifying the initial setup and enabling a standardized folder structure while pre-configuring essential settings for Lambda functions.</p> <p>Moreover, Lambda Forge fosters a modular code architecture, promoting unit and integration testing. A standout feature is the automatic generation of Swagger documentation from data classes within each Lambda function, a boon for developers. This enriches the framework, offering developers the tools to produce and access comprehensive API documentation with ease, thereby enhancing the development, management, and deployment journey of Lambda functions with Lambda Forge.</p>"},{"location":"page2/","title":"Getting Started","text":""},{"location":"page2/#install-and-configure-aws-cdk","title":"Install and Configure AWS CDK","text":"<p>Lambda Forge is built on top of AWS Cloud Development Kit (CDK) and it's essential for defining cloud infrastructure in code and provisioning it through AWS CloudFormation. Execute the following commands to install the AWS CDK globally and set up your AWS credentials:</p> <pre><code>npm install -g aws-cdk\naws configure\n</code></pre> <p>During the configuration, you will be prompted to enter your AWS Access Key ID, Secret Access Key, default region name, and output format.</p>"},{"location":"page2/#create-a-new-directory","title":"Create a new directory","text":"<pre><code>mkdir lambda_forge_demo\ncd lambda_forge_demo\n</code></pre>"},{"location":"page2/#create-a-new-virtual-environment","title":"Create a new virtual environment","text":"<pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre>"},{"location":"page2/#install-lambda-forge","title":"Install lambda-forge","text":"<pre><code>pip install lambda-forge --extra-index-url https://pypi.org/simple --extra-index-url https://test.pypi.org/simple/\n</code></pre>"},{"location":"page2/#verify-installation","title":"Verify Installation","text":"<p>Having successfully installed Lambda Forge, you are now ready to explore the capabilities of the Forge Command Line Interface (CLI). Begin by entering the following command to access the comprehensive list of available options and commands:</p> <pre><code>forge --help\n</code></pre>"},{"location":"page2/#create-a-new-github-repository","title":"Create a new Github Repository","text":"<p>Lambda Forge simplifies your workflow by automatically configuring a CI/CD pipeline within a GitHub repository. Therefore, our next step is to create a new repository on GitHub. This foundational setup enables Lambda Forge to seamlessly integrate and automate the development, testing, and deployment processes for your projects.</p>"},{"location":"page2/#create-a-new-project","title":"Create a new project:","text":"<p>Let's start a new project without generating docs initially.</p> <pre><code>forge project lambda-forge-demo --repo-owner \"$GITHUB-USER\" --repo-name \"$GITHUB-REPO\" --no-docs\n</code></pre> <p>Make sure to replace $GITHUB-USER and $GITHUB-REPO with your actual GitHub username and the repository name you established in the previous step.</p>"},{"location":"page2/#project-structure","title":"Project Structure","text":"<p>Upon creatig your project, several directories and files are automatically generated for you. This initial structure is designed to streamline the setup process and provide a solid foundation for further development.</p> <p>In the upcoming sections of this tutorial, we'll explore each of these components in detail. For now, familiarize yourself with the foundational structure that should resemble the following:</p> <pre><code>.\n\u251c\u2500\u2500 authorizers\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 functions\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 infra\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 services\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 api_gateway.py\n\u2502   \u2502   \u2514\u2500\u2500 aws_lambda.py\n\u2502   \u251c\u2500\u2500 stacks\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 dev_stack.py\n\u2502   \u2502   \u251c\u2500\u2500 lambda_stack.py\n\u2502   \u2502   \u251c\u2500\u2500 prod_stack.py\n\u2502   \u2502   \u2514\u2500\u2500 staging_stack.py\n\u2502   \u2514\u2500\u2500 stages\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 deploy.py\n\u251c\u2500\u2500 .coveragerc\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 app.py\n\u251c\u2500\u2500 cdk.json\n\u251c\u2500\u2500 pytest.ini\n\u2514\u2500\u2500 requirements.txt\n</code></pre>"},{"location":"page2/#creating-your-first-hello-world-function","title":"Creating Your First Hello World Function","text":"<p>Embarking on the journey with Lambda Forge, creating a public \"Hello World\" function is a fantastic way to get started. This function will serve as a simple demonstration of Lambda Forge's ability to quickly deploy serverless functions accessible via an HTTP endpoint. Here's how you can create your very first public Hello World function.</p> <pre><code>forge function hello_world --method \"GET\" --description \"A simple hello world\" --public\n</code></pre> <p>This command instructs Lambda Forge to generate a new lambda function named hello_world. The --method \"GET\" parameter specifies that this function will be accessible via an HTTP GET request. The --description provides a brief explanation of the function's purpose, and --public makes the function publicly accessible, allowing anyone with the URL to invoke it.</p>"},{"location":"page2/#understanding-the-function-structure","title":"Understanding the Function Structure","text":"<p>When you create a new function with Lambda Forge, it not only simplifies the creation process but also sets up a robust and organized file structure for your function. This structure is designed to support best practices in software development, including separation of concerns, configuration management, and testing. Let's break down the structure of the automatically generated hello_world function:</p> <pre><code>functions/\n\u2514\u2500\u2500 hello_world/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 config.py\n    \u251c\u2500\u2500 integration.py\n    \u251c\u2500\u2500 main.py\n    \u2514\u2500\u2500 unit.py\n</code></pre> <ul> <li><code>functions/</code> This directory is the root folder for all your Lambda functions. Each function has its own subdirectory within this folder.</li> <li><code>hello_world/</code> The hello_world subdirectory contains all the necessary files for your function to run, be configured, and tested.</li> <li><code>__init__.py</code> This file marks the directory as a Python package, allowing its modules to be imported elsewhere. It's a standard practice in Python to facilitate package organization.</li> <li><code>config.py</code> Holds the configuration settings for the function. These might include environment variables, resource identifiers, and other parameters critical for the function's operation. Keeping configuration separate from code is a best practice, as it enhances maintainability and scalability.</li> <li><code>integration.py</code> Contains integration tests that simulate the interaction of your function with external services or resources. These tests ensure that your function integrates correctly with other parts of the system and external dependencies.</li> <li><code>main.py</code> This is where the core logic of your Lambda function resides. The handler function, which AWS Lambda invokes when the function is executed, is defined here. You'll implement the functionality of your \"Hello World\" response in this file.</li> <li><code>unit.py</code> Contains unit tests for your function. Unit tests focus on testing individual parts of the function's code in isolation, ensuring that each component behaves as expected. This is crucial for identifying and fixing bugs early in the development process.</li> </ul>"},{"location":"page2/#why-this-structure-matters","title":"Why This Structure Matters","text":"<p>This organized approach offers several benefits:</p> <ul> <li>Maintainability: Separating different aspects of the function (such as configuration, testing, and core logic) makes it easier to manage and update the code.</li> <li>Scalability: As your application grows, having a consistent structure across functions allows for easier scaling and integration of new features or services.</li> <li>Testing: Including both unit and integration tests from the outset encourages a testing culture, leading to more robust and reliable code.</li> </ul> <p>As you continue to develop with Lambda Forge, this structure will help keep your projects organized and maintainable, regardless of their complexity or scale.</p>"},{"location":"page2/#configuring-your-lambda-function-dependencies","title":"Configuring Your Lambda Function Dependencies","text":""},{"location":"page2/#the-services-class","title":"The Services Class","text":"<p>Within the <code>infra/services/__init__.py</code> file, you'll find the Services class, a comprehensive resource manager designed to streamline the interaction with AWS services. This class acts as a dependency injector, enabling the easy and efficient configuration of AWS resources directly from your <code>config.py</code> files.</p> infra/services/__init__.py<pre><code>from infra.services.api_gateway import APIGateway\nfrom infra.services.aws_lambda import AWSLambda\n\nclass Services:\n\n    def __init__(self, scope, context) -&gt; None:\n        self.api_gateway = APIGateway(scope, context)\n        self.aws_lambda = AWSLambda(scope, context)\n</code></pre>"},{"location":"page2/#utilizing-the-services-class-in-configpy","title":"Utilizing the Services Class in config.py","text":"<p>In our Lambda Forge projects, the <code>config.py</code> file plays a crucial role in defining and configuring the dependencies required by a Lambda function. This includes everything from AWS Lambda layers, permissions to environment variables and DynamoDB tables. By passing an instance of Services to our configuration classes, we can seamlessly create and manage resources such as Lambda functions and API Gateway endpoints.</p> functions/hello_world/config.py<pre><code>from infra.services import Services\n\nclass HelloWorldConfig:\n    def __init__(self, services: Services) -&gt; None:\n\n        function = services.aws_lambda.create_function(\n            name=\"HelloWorld\",\n            path=\"./functions/hello_world\",\n            description=\"A simple hello world\"\n        )\n\n        services.api_gateway.create_endpoint(\"GET\", \"/hello_world\", function, public=True)\n</code></pre>"},{"location":"page2/#implementing-the-lambda-function","title":"Implementing the Lambda Function","text":"<p>Your Lambda function's implementation should be in the <code>main.py</code> file. Below is an example showcasing our simple HelloWorld function:</p> functions/hello_world/main.py<pre><code>import json\nfrom dataclasses import dataclass\n\n@dataclass\nclass Input:\n    pass\n\n@dataclass\nclass Output:\n    message: str\n\ndef lambda_handler(event, context):\n\n    return {\n        \"statusCode\": 200,\n        \"body\": json.dumps({\"message\": \"Hello World!\"})\n    }\n</code></pre> <p>The <code>Input</code> and <code>Output</code> data classes define the structure for each endpoint, laying the groundwork for generating the comprehensive Swagger documentation. This documentation precisely outlines the expected input and output data for every endpoint.</p> <p>Considering the project was initiated with the <code>--no-docs</code> flag, let's temporarily skip this documentation generation phase. However, we intend to revisit and implement documentation generation at a future point in this tutorial.</p>"},{"location":"page2/#deploying-your-lambda-function","title":"Deploying Your Lambda Function","text":"<p>To deploy your Lambda function, you should integrate the Config class within the <code>infra/stacks/lambda_stack.py</code> file.</p> <p>The Forge CLI streamlines this process by automatically incorporating it for you.</p> infra/stacks/lambda_stack.py<pre><code>from aws_cdk import Stack\nfrom constructs import Construct\nfrom infra.services import Services\nfrom lambda_forge import release\nfrom functions.hello_world.config import HelloWorldConfig\n\n\n@release\nclass LambdaStack(Stack):\n    def __init__(self, scope: Construct, context, **kwargs) -&gt; None:\n\n        super().__init__(scope, f\"{context.name}-CDK\", **kwargs)\n\n        self.services = Services(self, context)\n\n        # HelloWorld\n        HelloWorldConfig(self.services)\n</code></pre>"},{"location":"page2/#create-a-github-personal-access-token","title":"Create a GitHub Personal Access Token","text":"<p>Lambda Forge uses CodePipeline to interact with your GitHub repository. To enable this, generate a GitHub personal access token by following these steps:</p> <ol> <li>Navigate to \"Developer Settings\" in your GitHub account.</li> <li>Select \"Personal access tokens,\" then \"Tokens (classic).\"</li> <li>Click \"Generate new token,\" ensuring the \"repo\" scope is selected for full control of private repositories.</li> <li>Complete the token generation process.</li> </ol> <p>Your token will follow this format: <code>ghp_********************************</code></p>"},{"location":"page2/#store-the-token-on-aws-secrets-manager","title":"Store the token on AWS Secrets Manager","text":"<p>Save this token in AWS Secrets Manager as <code>plain text</code> using the precise name github-token. This specific naming is vital as it corresponds to the default identifier that the CDK looks for within your AWS account.</p>"},{"location":"page2/#push-your-code-to-github","title":"Push Your Code To Github","text":"<p>With all the required settings now in place, we're ready to upload our code to the GitHub repository.</p> <p>Lambda Forge is designed to support a multi-stage deployment process, automatically creating environments for Production, Staging and Development. These environments correspond to the <code>main</code>, <code>staging</code>, and <code>dev</code> branches, respectively.</p> <p>Let's proceed by setting up these branches:</p> <pre><code># Initialize the Git repository\ngit init\ngit add .\n\n# Commit the changes\ngit commit -m \"Initial commit\"\n\n# Set the remote repository\ngit remote add origin git@github.com:$GITHUB_USER/$GITHUB_REPO.git\n\n# Create, checkout, and push the 'main' branch\ngit checkout -b main\ngit push -u origin main\n\n# Create, checkout, and push the 'staging' branch\ngit checkout -b staging\ngit push -u origin staging\n\n# Create and push the 'dev' branch\ngit branch -M dev\ngit push -u origin dev\n</code></pre>"},{"location":"page2/#deploying-the-stacks","title":"Deploying the Stacks","text":"<p>After pushing your code to GitHub, the next step is deploying your stacks to AWS using the AWS Cloud Development Kit (CDK). Deploy your stacks by running the following commands in your terminal:</p> <pre><code>cdk synth\ncdk deploy --all --require-approval never\n</code></pre> <p>These commands kick off the creation of three separate stacks in AWS CloudFormation:</p> <ul> <li>Dev-Lambda-Forge-Demo-Stack: For the development stage.</li> <li>Staging-Lambda-Forge-Demo-Stack: For the staging stage.</li> <li>Prod-Lambda-Forge-Demo-Stack: For the production stage.</li> </ul> <p>Every resource created on AWS by Lambda Forge adhere to a convention that incorporates the deployment stage, project name and the resource name, ensuring a clear and systematic identification across the project. The project name, a central element of this naming convention, is specified in the <code>cdk.json</code> file, which Forge automatically configured.</p> cdk.json<pre><code>...\n    \"region\": \"us-east-2\",\n    \"account\": \"\",\n    \"name\": \"Lambda-Forge-Demo\",\n    \"repo\": {\n      \"owner\": \"$GITHUB-USER\",\n      \"name\": \"$GITHUB-REPO\"\n    },\n...\n</code></pre> <p>Following a successful deployment, three corresponding pipelines are automatically generated for each stage:</p> <ul> <li>Dev-Lambda-Forge-Demo-Pipeline</li> <li>Staging-Lambda-Forge-Demo-Pipeline</li> <li>Prod-Lambda-Forge-Demo-Pipeline</li> </ul> <p>You can view these pipelines by navigating to the AWS CodePipeline dashboard. </p> <p></p>"},{"location":"page2/#customizing-pipeline-steps","title":"Customizing Pipeline Steps","text":"<p>In Lambda Forge, pipelines are defined within their specific stack files located at <code>infra/stacks/dev_stack.py</code>, <code>infra/stacks/staging_stack.py</code>, and <code>infra/stacks/prod_stack.py</code>. Below is an outline of the default steps included in each pipeline, along with details on how they function and how you can interact with them.</p> <ul> <li> <p>Coverage: Measures the percentage of your production code covered by unit tests, failing if coverage falls below 80% as default. To view the coverage report, navigate to <code>Details -&gt; Reports</code> in CodePipeline.</p> </li> <li> <p>Unit Tests: Runs unit tests to validate the functionality of individual components within your code. Access the unit test report via <code>Details -&gt; Reports</code> in CodePipeline.</p> </li> <li> <p>Validate Docs: Verifies that all Lambda functions invoked by API Gateway have their Input and Output data classes correctly defined in the <code>main.py</code> file.</p> </li> <li> <p>Validate Integration Tests: This step ensures that all endpoints triggered by the API Gateway are covered by at least one integration test. To achieve this, use the custom decorator <code>@pytest.mark.integration</code> and specify the method and endpoint arguments to declare that the test covers a specific endpoint.</p> </li> <li> <p>Generate Docs: Automatically produces Swagger documentation for all API Gateway endpoints. This requires <code>Input</code> and <code>Output</code> data classes for each Lambda function in the <code>main.py</code> file. Documentation is deployed directly to API Gateway and is accessible at the <code>/docs</code> endpoint.</p> </li> <li> <p>Integration Tests: Performs integration testing to assess the system's overall functionality. Access the integration test report through <code>Details -&gt; Reports</code> in CodePipeline.</p> </li> </ul> <p>Lambda Forge provides a suggested pipeline configuration, emphasizing flexibility in its design. You're encouraged to customize these pipelines to fit your project's needs. Whether adding new steps, adjusting existing ones, or reordering them, the framework is designed to accommodate your project's specific requirements. This level of customization ensures that your pipelines align closely with your development, testing, and deployment strategies, providing a robust foundation for your application's continuous integration and delivery processes.</p> <p>After the pipelines have executed, you may notice that while the Development pipeline succeeds, the Staging and Production pipelines fail.</p> <p></p> <p>This failure is expected, It occurs because the integration test step attempts to send a GET request to the deployed Lambda function. However, since the Stack has just been created, the Lambda function's URL is not yet available, causing the test to fail.</p> functions/hello_world/integration.py<pre><code>import pytest\nimport requests\nfrom lambda_forge.constants import BASE_URL\n\n@pytest.mark.integration(method=\"GET\", endpoint=\"/hello_world\")\ndef test_hello_world_status_code_is_200():\n\n    response = requests.get(url=f\"{BASE_URL}/hello_world\")\n\n    assert response.status_code == 200\n</code></pre>"},{"location":"page2/#accessing-your-lambda-function","title":"Accessing Your Lambda Function","text":"<p>Note that the <code>Integration_Test</code> step failed after the deployment in the staging pipeline.</p> <p></p> <p>This means that both Dev and the Staging Lambda function are successfully deployed.</p> <p>In this tutorial, we will use the staging URL to test our endpoints, considering it as a pre-production layer. Feel free to utilize the development URL instead if it suits your case better.</p> <p>Navigate to the AWS Lambda section on AWS and search for the Staging-Lambda-Forge-Demo-HelloWorld function in the list of Lambda functions. </p> <p></p> <p>Once you've found your function, click on it to view its details. Proceed by selecting the Configuration tab, followed by Triggers to uncover the integration points.</p> <p></p> <p>In this tutorial, the generated URL is:</p> <p>https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging/hello_world.</p> <p>By following the link provided, you should be greeted by a simple \"Hello World\" message in your web browser, indicating that your Lambda function is operational and accessible via the URL generated by API Gateway.</p> <pre><code>{\n  \"message\": \"Hello World!\"\n}\n</code></pre>"},{"location":"page2/#configuring-the-base-url-for-integration-tests","title":"Configuring the BASE URL for Integration Tests","text":"<p>With the Lambda function's URL at hand, we identify that the segment before <code>/hello_world</code> acts as the BASE URL. For the purposes of this tutorial, the BASE URL is <code>https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging</code>. This is the URL you need to copy.</p> <p>Proceed to incorporate this URL into your project's configuration by setting it as the value for <code>base_url</code> in your <code>cdk.json</code> file.</p> cdk.json<pre><code>...\n\"region\": \"us-east-2\",\n\"account\": \"\",\n\"name\": \"Lambda-Forge-Demo\",\n\"repo\": {\n    \"owner\": \"$GITHUB-USER\",\n    \"name\": \"$GITHUB-REPO\"\n},\n\"bucket\": \"\",\n\"coverage\": 80,\n\"base_url\": \"https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging\"\n...\n</code></pre>"},{"location":"page2/#pushing-updated-code-to-github","title":"Pushing Updated Code to GitHub","text":"<p>With the BASE URL configured for our integration tests, it's time to push the updated code to GitHub and aim for successful integration test outcomes across all deployment stages.</p> <p>Follow these steps to commit your changes and deploy them across the development, staging, and production branches:</p> <pre><code># Add changes to the staging area\ngit add .\n\n# Commit the changes with a descriptive message\ngit commit -m \"Configure BASE URL for integration tests\"\n\n# Push changes to the 'dev' branch.\ngit push origin dev\n\n# Switch to the 'staging' branch, merge changes from 'dev', and push\ngit checkout staging\ngit merge dev\ngit push origin staging\n\n# Switch to the 'main' branch, merge changes from 'staging', and push\ngit checkout main\ngit merge staging\ngit push origin main\n</code></pre> <p>After executing these commands, all associated pipelines should be triggered once again.</p> <p></p> <p>Once the execution of all pipelines is complete, you should observe that all stages have successfully passed.</p> <p></p> <p></p> <p>Congratulations! \ud83c\udf89 You've successfully deployed your very first Lambda function across three distinct stages using Lambda Forge! \ud83d\ude80</p> <p>In this tutorial, the links are:</p> <ul> <li>Dev: https://gxjca0e395.execute-api.us-east-2.amazonaws.com/dev/hello_world</li> <li>Staging: https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging/hello_world</li> <li>Prod: https://s6zqhu2pg1.execute-api.us-east-2.amazonaws.com/prod/hello_world</li> </ul>"},{"location":"page3/","title":"Generating Docs","text":"<p>With our Lambda Function now deployed across three distinct stages, the next step involves creating documentation for our endpoints.</p>"},{"location":"page3/#setting-up-a-s3-bucket-for-documentation","title":"Setting Up a S3 Bucket for Documentation","text":"<p>Create an Amazon S3 bucket to serve as the primary storage for your documentation files. Follow these steps to create your S3 bucket:</p> <ol> <li>Access the AWS Management Console: Open the Amazon S3 console at https://console.aws.amazon.com/s3/.</li> <li>Create a New Bucket: Click on the \"Create bucket\" button. It's important to note that each bucket's name must be globally unique across all of Amazon S3.</li> <li>Set Bucket Name: Choose a unique and descriptive name for your bucket. This name will be crucial for accessing your documentation files. Remember, once a bucket name is set, it cannot be changed.</li> <li>Choose a Region: Select an AWS Region for your bucket. Choose the same region defined in your <code>cdk.json</code>.</li> <li>Configure Options: You may leave the default settings or configure additional options like versioning, logging, or add tags according to your needs.</li> <li>Review and Create: Before creating the bucket, review your settings. Once everything is confirmed, click \"Create bucket\".</li> </ol> <p>Once the bucket is created, update your <code>cdk.json</code> file with the bucket's name as shown below:</p> cdk.json<pre><code>...\n\"region\": \"us-east-2\",\n\"account\": \"\",\n\"name\": \"Lambda-Forge-Demo\",\n\"repo\": {\n    \"owner\": \"$GITHUB-USER\",\n    \"name\": \"$GITHUB-REPO\"\n},\n\"bucket\": \"$S3-BUCKET-NAME\",\n\"coverage\": 80,\n...\n</code></pre>"},{"location":"page3/#activating-docs","title":"Activating Docs","text":"<p>To activate documentation generation, navigate to the <code>deploy.py</code> file located at <code>infra/stages/deploy.py</code>. Modify the <code>enabled</code> parameter by setting it from <code>False</code> to <code>True</code> on line 13, as demonstrated below:</p> infra/stages/deploy.py<pre><code>import aws_cdk as cdk\nfrom constructs import Construct\n\nfrom infra.stacks.lambda_stack import LambdaStack\n\n\nclass DeployStage(cdk.Stage):\n    def __init__(self, scope: Construct, context, **kwargs):\n        super().__init__(scope, context.stage, **kwargs)\n\n        lambda_stack = LambdaStack(self, context)\n\n        lambda_stack.services.api_gateway.create_docs(enabled=True, authorizer=None)\n</code></pre> <p>By default, Lambda Forge does not include documentation for the Development stage.</p> <p>Since the project was initiated using the <code>--no-docs</code> flag, the generate docs step is absent from the post deployment phase in both the Staging and Production stacks.</p> <p>To activate the docs, update the relevant sections in your stack configurations as follows:</p> <p>In your Staging stack, enable generate docs by including it in the <code>post</code> array of the pipeline configuration. The updated section should look like this:</p> infra/stacks/staging_stack.py<pre><code>    # post\n    generate_docs = steps.generate_docs()\n    integration_tests = steps.run_integration_tests()\n\n    pipeline.add_stage(\n        DeployStage(self, context),\n        pre=[\n            unit_tests,\n            coverage,\n            validate_integration_tests,\n            validate_docs,\n        ],\n        post=[integration_tests, generate_docs], # Generate docs enabled\n    )\n</code></pre> <p>Similarly, for the Production stack, ensure that generate docs is enabled by adding it to the post section of your pipeline setup:</p> infra/stacks/prod_stack.py<pre><code>    # post\n    generate_docs = steps.generate_docs()\n\n    pipeline.add_stage(\n        DeployStage(self, context),\n        post=[generate_docs], # Generate docs enabled\n    )\n</code></pre> <p>At this point, we have all the necessary components to automatically generate our docs.</p> <p>To proceed, commit your changes and push them to GitHub using the following commands:</p> <pre><code>git add .\n\ngit commit -m \"Adding documentation support\"\n\n# Push changes to the 'dev' branch\ngit push origin dev\n\n# Merge 'dev' into 'staging' and push\ngit checkout staging\ngit merge dev\ngit push origin staging\n\n# Finally, merge 'staging' into 'main' and push\ngit checkout main\ngit merge staging\ngit push origin main\n</code></pre> <p>Upon successful completion of the pipeline, the Swagger documentation for your endpoints can be accessed via the <code>/docs</code> path. This documentation provides comprehensive details about the available endpoints, including request formats, response structures, and query parameters.</p> <p>You can view the Swagger documentation at the following URLs for each environment:</p> <ul> <li>Staging Environment: https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging/docs</li> <li>Production Environment: https://s6zqhu2pg1.execute-api.us-east-2.amazonaws.com/prod/docs</li> </ul> <p>This code snippet below demonstrates all the types of data you can expect to work with, including simple data types, lists, custom objects, optional fields, and literal types, offering a clear understanding of the input and output contracts for the API.</p> <pre><code>from dataclasses import dataclass\nfrom typing import List, Optional, Literal\n\n@dataclass\nclass Path:\n    id: str # If your endpoint requires a path parameter in the URL, document it here\n\n@dataclass\nclass Object:\n    a_string: str\n    an_int: int\n\n@dataclass\nclass Input:\n    a_string: str\n    an_int: int\n    a_boolean: bool\n    a_list: List[str]\n    an_object: Object\n    a_list_of_object: List[Object]\n    a_literal: Literal[\"a\", \"b\", \"c\"]\n    an_optional: Optional[str]\n\n@dataclass\nclass Output:\n    pass\n</code></pre> <p>You may have observed that our documentation endpoint is currently public. While in some scenarios, having public documentation is desirable, in others, it can pose a significant security risk. In the following section, we will explore methods to secure this and other endpoints, making them accessible only through an authorizer.</p>"},{"location":"page4/","title":"Private Endpoints","text":"<p>Given our current setup, all endpoints are accessible via the internet, which may or may not align with the intended use case of your application.</p> <p>Let's proceed to learn how to configure these endpoints to be private.</p> <p>First, let's begin by creating a new authorizer function with the following command:</p> <pre><code>forge authorizer docs --description \"Authorizer for Swagger Documentation\"\n</code></pre> <p>This command instructs the forge CLI tool to create a new authorizer function named docs.</p>"},{"location":"page4/#authorizer-structure","title":"Authorizer Structure","text":"<p>Authorizers, while closely resembling Lambda Functions in structure, fulfill a distinct role. Their primary function is to act as an intermediary layer that authenticates requests made to Lambda Functions, ensuring that only authorized requests are processed.</p> <p>Let's examine the structure of an authorizer more closely:</p> <pre><code>authorizers\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u2514\u2500\u2500 unit.py\n\u2514\u2500\u2500 utils\n    \u2514\u2500\u2500 __init__.py\n</code></pre> <ul> <li><code>authorizers/</code> This directory serves as the central hub for all authorizer functions, analogous to how the <code>functions/</code> directory houses Lambda functions. Each distinct authorizer is allocated its own subdirectory within this folder.</li> <li><code>docs/</code> The <code>docs</code> subdirectory is specifically designed for the authorizer related to the 'docs' endpoint. It includes everything needed for the authorizer to authenticate requests, manage configurations, and perform testing.</li> <li><code>__init__.py</code> Marks the directory as a Python package, enabling its modules to be imported elsewhere within the project.</li> <li><code>config.py</code> Contains the configuration settings for the authorizer, such as environmental variables and access control parameters. Keeping the configuration separate from the core logic is a best practice that enhances code maintainability and adaptability.</li> <li><code>main.py</code> Houses the main logic for the authorizer, detailing how incoming requests are verified. This file is where you define the procedures for credential validation and access authorization.</li> <li><code>unit.py</code> Focused on unit testing for the authorizer, these tests ensure that each part of the authorizer's code operates as expected independently, which is essential for early bug detection and reliable functionality.</li> <li><code>utils/</code> Provides utility functions that are used by the authorizers, offering common functionalities or resources that can be leveraged across various authorizers to facilitate development and maintenance.</li> </ul>"},{"location":"page4/#configuring-your-authorizer","title":"Configuring Your Authorizer","text":"<p>Similar to lambda functions in terms of setup, authorizers diverge in their application. Instead of establishing an endpoint on API Gateway, an authorizer is configured to control access to one or more endpoints.</p> authorizers/docs/config.py<pre><code>from infra.services import Services\n\nclass DocsAuthorizerConfig:\n    def __init__(self, services: Services) -&gt; None:\n\n        function = services.aws_lambda.create_function(\n            name=\"DocsAuthorizer\",\n            path=\"./authorizers/docs\",\n            description=\"Authorizer for Swagger Documentation\"\n        )\n\n        services.api_gateway.create_authorizer(function, name=\"docs\", default=False)\n</code></pre> <p>Actually, Lambda Forge treats all lambda functions as private by default. That's why we had to use the <code>--public</code> flag in our initial forge command to make the function accessible without authentication. Without this flag, we would have been required to implement an authorizer for user authentication.</p>"},{"location":"page4/#implementing-the-authorizer","title":"Implementing The Authorizer","text":"<p>Forge automatically generates a basic implementation of an AWS Lambda authorizer. This example is intended solely for demonstration and learning purposes, and it is critical to devise a comprehensive and secure authentication mechanism suitable for your application's specific security needs. For demonstration, the authorizer checks a custom header for a specific secret value to decide on granting or denying access.</p> <p>Important Note: The example below employs a simple secret key for authorization, which is not recommended for production environments. It is crucial to replace this logic with a robust, secure authorization strategy before deploying your application.</p> authorizers/docs/main.py<pre><code>def lambda_handler(event, context):\n\n    # ATTENTION: The example provided below is strictly for demonstration purposes and should NOT be deployed in a production environment.\n    # It's crucial to develop and integrate your own robust authorization mechanism tailored to your application's security requirements.\n    # To utilize the example authorizer as a temporary placeholder, ensure to include the following header in your requests:\n\n    # Header:\n    # secret: CRMdDRMA4iW4xo9l38pACls7zsHYfp8T7TLXtucysb2lB5XBVFn8\n\n    # Remember, security is paramount. This placeholder serves as a guide to help you understand the kind of information your custom authorizer should authenticate.\n    # Please replace it with your secure, proprietary logic before going live. Happy coding!\n\n    secret = event[\"headers\"].get(\"secret\")\n\n    SECRET = \"CRMdDRMA4iW4xo9l38pACls7zsHYfp8T7TLXtucysb2lB5XBVFn8\"\n    effect = \"allow\" if secret == SECRET else \"deny\"\n\n    policy = {\n        \"policyDocument\": {\n            \"Version\": \"2012-10-17\",\n            \"Statement\": [\n                {\n                    \"Action\": \"execute-api:Invoke\",\n                    \"Effect\": effect,\n                    \"Resource\": \"*\"\n                }\n            ],\n        },\n    }\n    return policy\n</code></pre> <p>As illustrated in the code snippet above, the authorizer is designed to check for a specific header named <code>secret</code>, expecting it to contain the key <code>CRMdDRMA4iW4xo9l38pACls7zsHYfp8T7TLXtucysb2lB5XBVFn8</code>.</p> <p>This key serves as a simple form of authentication, granting or denying access based on its presence and accuracy in the request headers.</p> <p>The token mentioned is automatically generated by Forge, meaning the specific token you encounter during your implementation will differ from the example provided. Please be mindful of this distinction as you proceed.</p>"},{"location":"page4/#adding-authorizer-to-lambda-stack","title":"Adding Authorizer To Lambda Stack","text":"<p>Just like the functions, an authorizer needs to be initialized within the LambdaStack.</p> <p>Fortunately, Forge takes care of this automatically for you.</p> infra/stacks/lambda_stack.py<pre><code>from aws_cdk import Stack\nfrom constructs import Construct\nfrom infra.services import Services\nfrom lambda_forge import release\nfrom authorizers.docs.config import DocsAuthorizerConfig\nfrom functions.hello_world.config import HelloWorldConfig\n\n\n@release\nclass LambdaStack(Stack):\n    def __init__(self, scope: Construct, context, **kwargs) -&gt; None:\n\n        super().__init__(scope, f\"{context.name}-Lambda-Stack\", **kwargs)\n\n        self.services = Services(self, context)\n\n        # Authorizers\n        DocsAuthorizerConfig(self.services)\n\n        # HelloWorld\n        HelloWorldConfig(self.services)\n</code></pre>"},{"location":"page4/#attaching-the-authorizer-to-the-docs-endpoints","title":"Attaching The Authorizer To The Docs Endpoints","text":"<p>Given that the resources developed in this tutorial serve as public demonstrations of the deployment process, we will not secure the previously created endpoint, allowing it to remain accessible to other readers. Instead, we'll introduce protection by setting up a new Swagger documentation under a separate endpoint.</p> <p>However, if you prefer, you're welcome to secure the original documentation endpoint instead of establishing a new one.</p> <p>To integrate the new authorizer or to update an existing docs endpoint to include authorization, navigate to your <code>infra/stages/deploy.py</code> file. Here, you will either add a new endpoint for the docs with authorization enabled or update the current one.</p> <p>The example below shows how to add a new endpoint <code>/docs/private</code> that is protected by the docs authorizer, while keeping the original docs endpoint public for demonstration purposes:</p> infra/stages/deploy.py<pre><code>import aws_cdk as cdk\nfrom constructs import Construct\n\nfrom infra.stacks.lambda_stack import LambdaStack\n\n\nclass DeployStage(cdk.Stage):\n    def __init__(self, scope: Construct, context, **kwargs):\n        super().__init__(scope, context.stage, **kwargs)\n\n        lambda_stack = LambdaStack(self, context)\n\n        # Keep the original docs endpoint public\n        lambda_stack.services.api_gateway.create_docs(enabled=True, authorizer=None)\n\n        # Add a new, private docs endpoint at /docs/private\n        lambda_stack.services.api_gateway.create_docs(enabled=True, authorizer=\"docs\", endpoint=\"/docs/private\")\n</code></pre> <p>Keep in mind that the authorizer you specify when enabling the docs endpoint must match the exact name assigned to the authorizer within the authorizer configuration class created previously.</p> authorizers/docs/config.py<pre><code>        function = services.aws_lambda.create_function(\n            name=\"DocsAuthorizer\",\n            path=\"./authorizers/docs\",\n            description=\"Authorizer to be used by swagger\"\n        )\n\n        services.api_gateway.create_authorizer(function, name=\"docs\")\n</code></pre>"},{"location":"page4/#publish-your-changes-to-github","title":"Publish Your Changes to GitHub","text":"<p>With all components now properly configured, the next step is to publish your updates to GitHub. Execute the following commands to add, commit, and push your changes across the various branches, ensuring your repository reflects the latest state of your project:</p> <pre><code># Stage all changes for commit\ngit add .\n\n# Commit your changes with a descriptive message\ngit commit -m \"Implemented private documentation endpoint\"\n\n# Push the changes to the 'dev' branch\ngit push origin dev\n\n# Switch to the 'staging' branch, merge changes from 'dev', and push\ngit checkout staging\ngit merge dev\ngit push origin staging\n\n# Switch to the 'main' branch, merge changes from 'staging', and push, completing the workflow\ngit checkout main\ngit merge staging\ngit push origin main\n</code></pre> <p>Once the deployment pipelines conclude, you'll have access to the newly secured documentation endpoint, protected by the authorizer.</p> <ul> <li>Staging: https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging/docs/private</li> <li>Prod: https://s6zqhu2pg1.execute-api.us-east-2.amazonaws.com/prod/docs/private</li> </ul> <p>Attempting to access the above URLs directly will result in the following message:</p> <pre><code>{\n  \"Message\": \"User is not authorized to access this resource with an explicit deny\"\n}\n</code></pre> <p>This response confirms that the authorizer is operational, effectively restricting access to unauthorized requests.</p> <p>However, by including the appropriate secret in your request headers, you can gain access to the documentation.</p> <p>To view the documentation, copy the following cURL commands and paste them into your preferred API testing tool, such as Insomnia, Postman, or any other tool of your choice:</p> <p>For Staging:</p> Staging<pre><code>curl --request GET \\\n  --url https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging/docs/private \\\n  --header 'secret: CRMdDRMA4iW4xo9l38pACls7zsHYfp8T7TLXtucysb2lB5XBVFn8'\n</code></pre> <p>For Production:</p> Prod<pre><code>curl --request GET \\\n  --url https://s6zqhu2pg1.execute-api.us-east-2.amazonaws.com/prod/docs/private \\\n  --header 'secret: CRMdDRMA4iW4xo9l38pACls7zsHYfp8T7TLXtucysb2lB5XBVFn8'\n</code></pre> <p>This process demonstrates the effectiveness of the authorizer in safeguarding your documentation, allowing only those with the correct secret to view it.</p>"},{"location":"page4/#default-authorizer","title":"Default Authorizer","text":"<p>As mentioned before, Lambda Forge treats all functions as private by default. Consequently, unless explicitly declared public, functions are presumed to necessitate an authorizer for access control.</p> <p>To streamline the process and eliminate the need to assign an authorizer to each Lambda function individually, you can designate a single authorizer as the default. This approach ensures that all non-public Lambda functions automatically inherit this default authorizer, simplifying the setup for access control.</p> <p>To establish a default authorizer, use the following command:</p> <pre><code>forge authorizer default --description \"Default Authorizer\" --default\n</code></pre> <p>This command configures a new authorizer named <code>default</code> within Forge, marking it as the default option. Consequently, any Lambda functions not explicitly associated with a different authorizer will automatically use this default authorizer for access control.</p> <p>Upon executing the command to create a default authorizer, a new directory structure is established under the authorizers folder, mirroring the organized approach taken for other components in the project. The structure now includes a dedicated folder for the <code>default</code> authorizer, alongside the <code>docs</code> authorizer.</p> <pre><code>authorizers\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 default\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u2514\u2500\u2500 unit.py\n\u251c\u2500\u2500 docs\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u2514\u2500\u2500 unit.py\n\u2514\u2500\u2500 utils\n    \u2514\u2500\u2500 __init__.py\n</code></pre> <p>Let's examine the details of the <code>DefaultAuthorizerConfig</code> class recently created by Forge.</p> authorizers/default/config.py<pre><code>from infra.services import Services\n\nclass DefaultAuthorizerConfig:\n    def __init__(self, services: Services) -&gt; None:\n\n        function = services.aws_lambda.create_function(\n            name=\"DefaultAuthorizer\",\n            path=\"./authorizers/default\",\n            description=\"Default Authorizer\"\n        )\n\n        services.api_gateway.create_authorizer(function, name=\"default\", default=True)\n</code></pre> <p>The <code>default=True</code> parameter on line 12 explicitly designates this authorizer as the default for all non-public Lambda functions, automatically applying it as their access control mechanism.</p> <p>Just like the docs authorizer, Forge has created a new secret key for the default authorizer. For this tutorial, the header expected in the request is:</p> <p><code>secret</code>: <code>Jmat02QiRNLTRVRWSUxBoljTxzpnHnzZcz0iFAXY4s1vgvO8m36q</code></p>"},{"location":"page4/#private-function","title":"Private Function","text":"<p>Now let's create a new private function.</p> <pre><code>Forge function private --method \"GET\" --description \"A private function\"\n</code></pre> <p>Upon creating a new private function using Forge with the specified command, the project's function structure is expanded to include this newly private function alongside the existing ones.</p> <pre><code>functions\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 hello_world\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u251c\u2500\u2500 integration.py\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u2514\u2500\u2500 unit.py\n\u2514\u2500\u2500 private\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 config.py\n    \u251c\u2500\u2500 integration.py\n    \u251c\u2500\u2500 main.py\n    \u2514\u2500\u2500 unit.py\n</code></pre> <p>Let's examine the PrivateConfig class that Forge has generated for us.</p> functions/private/config.py<pre><code>from infra.services import Services\n\nclass PrivateConfig:\n    def __init__(self, services: Services) -&gt; None:\n\n        function = services.aws_lambda.create_function(\n            name=\"Private\",\n            path=\"./functions/private\",\n            description=\"A private function\",\n        )\n\n        services.api_gateway.create_endpoint(\"GET\", \"/private\", function)\n</code></pre> <p>Within this configuration class, we are establishing a new endpoint to handle a GET request at the <code>/private</code> path. Importantly, there's no clear declaration of this function as public, nor is an authorizer explicitly defined for it. Nonetheless, due to the prior configuration of a default authorizer, this function will automatically fall under its protection.</p> <p>This approach underscores the utility and efficiency of setting a default authorizer safeguarding new functions by default, thereby enhancing security without necessitating manual authorizer configuration for each new endpoint.</p> <p>Let's make some adjustments to the response returned by this Lambda function:</p> functions/private/main.py<pre><code>def lambda_handler(event, context):\n\n    return {\n        \"statusCode\": 200,\n        \"body\": json.dumps({\"message\": \"Hello From Private!\"})\n    }\n</code></pre> <p>Additionally, let's revise the unit tests and the integration tests to accurately represent the modifications we've implemented in our code.</p> functions/private/unit.py<pre><code>import json\nfrom .main import lambda_handler\n\ndef test_lambda_handler():\n\n    response = lambda_handler(None, None)\n\n    assert response[\"body\"] == json.dumps({\"message\": \"Hello From Private!\"})\n</code></pre> functions/private/integration.py<pre><code>import pytest\nimport requests\nfrom lambda_forge.constants import BASE_URL\n\n@pytest.mark.integration(method=\"GET\", endpoint=\"/private\")\ndef test_private_status_code_with_no_header_is_403():\n\n    response = requests.get(url=f\"{BASE_URL}/private\")\n\n    assert response.status_code == 403\n\n\n@pytest.mark.integration(method=\"GET\", endpoint=\"/private\")\ndef test_private_status_code_with_valid_header_is_200():\n\n    headers = {\n        \"secret\": \"Jmat02QiRNLTRVRWSUxBoljTxzpnHnzZcz0iFAXY4s1vgvO8m36q\"\n    }\n\n    response = requests.get(url=f\"{BASE_URL}/private\", headers=headers)\n\n    assert response.status_code == 200\n</code></pre> <p>Next, let's proceed to upload our updates to GitHub.</p> <pre><code># Add all changes to the staging area\ngit add .\n\n# Commit the staged changes with a clear message\ngit commit -m \"Implemented a private function with default authorizer\"\n\n# Push the committed changes to the 'dev' branch\ngit push origin dev\n\n# Transition to the 'staging' branch to integrate the latest developments\ngit checkout staging\ngit merge dev\ngit push origin staging\n\n# Finally, update the 'main' branch with the changes from 'staging' and push the update to complete the deployment process\ngit checkout main\ngit merge staging\ngit push origin main\n</code></pre> <p>Following the successful execution of our deployment pipelines, our private lambda function is now live:</p> <ul> <li>Staging: https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging/private</li> <li>Prod: https://s6zqhu2pg1.execute-api.us-east-2.amazonaws.com/prod/private</li> </ul> <p>Attempting to access these URLs directly via your web browser will result in the following message, indicating unauthorized access:</p> <pre><code>{\n  \"Message\": \"User is not authorized to access this resource with an explicit deny\"\n}\n</code></pre> <p>However, by including the required secret in the header of your request, you can successfully retrieve the content. Here's how you can use curl to access the deployed Lambda function in both environments:</p> Staging<pre><code>curl --request GET \\\n  --url https://8kwcovaj0f.execute-api.us-east-2.amazonaws.com/staging/private \\\n  --header 'secret: Jmat02QiRNLTRVRWSUxBoljTxzpnHnzZcz0iFAXY4s1vgvO8m36q'\n</code></pre> Prod<pre><code>curl --request GET \\\n  --url https://s6zqhu2pg1.execute-api.us-east-2.amazonaws.com/prod/private \\\n  --header 'secret: Jmat02QiRNLTRVRWSUxBoljTxzpnHnzZcz0iFAXY4s1vgvO8m36q'\n</code></pre> <p>This demonstrates the effectiveness of our authorizer in securing the private Lambda function, allowing access only to those with the correct secret header.</p>"},{"location":"page4/#using-specific-authorizers-for-endpoints","title":"Using Specific Authorizers for Endpoints","text":"<p>In case you need to secure an endpoint with a particular authorizer, you can achieve this by specifying the authorizer's name during its setup in the configuration class.</p> <p>Here\u2019s how you would configure a specific authorizer for an endpoint:</p> functions/private/config.py<pre><code>from infra.services import Services\n\nclass PrivateConfig:\n    def __init__(self, services: Services) -&gt; None:\n\n        function = services.aws_lambda.create_function(\n            name=\"Private\",\n            path=\"./functions/private\",\n            description=\"A private function\",\n        )\n\n        # Specify the 'docs' authorizer for the '/private' endpoint\n        services.api_gateway.create_endpoint(\"GET\", \"/private\", function, authorizer=\"docs\")\n</code></pre> <p>By implementing this configuration, the <code>/private</code> function would be secured using the same authorizer as the <code>/docs</code> endpoints.</p> <p>Please note, this change is presented for illustrative purposes to demonstrate how to apply a non-default authorizer. Consequently, we will not commit this alteration and will continue to secure the <code>/private</code> endpoint with the default authorizer.</p>"},{"location":"page5/","title":"Building a CRUD Application","text":"<p>Diving deeper into AWS Resources, we're setting out to build a CRUD application that records names and their possible nicknames.</p> <p>After the user submit a name, the application, through the Behind The Name API, will search for potential nicknames and save them on Dynamo DB.</p>"},{"location":"page5/#creating-an-api-key-on-behind-the-name-api","title":"Creating an API Key on Behind The Name API","text":"<p>To utilize the Behind The Name API, which enables retrieval of detailed information on names, users must first generate an API key. This key is obtained by registering on the Behind The Name website and requesting access.</p> <p>Following registration, navigate to https://www.behindthename.com/api/gateway.php to create your API key.</p>"},{"location":"page5/#store-the-api-key-on-aws-secrets-manager","title":"Store the API Key on AWS Secrets Manager","text":"<p>Store the API key in AWS Secrets Manager to prevent the key from being hard-coded into your application's source code, enhancing security and maintaining the confidentiality of your API key.</p>"},{"location":"page5/#integrating-secrets-manager-into-your-lambda-service","title":"Integrating Secrets Manager into Your Lambda Service","text":"<p>To enable interaction with AWS Secrets Manager within our Lambda functions, it's essential to incorporate it into our Service class. This ensures accessibility across all configuration files.</p> <p>Execute the command below to add Secrets Manager as a new service:</p> <pre><code>forge service secrets_manager\n</code></pre> <p>Upon running this command, a new <code>secrets_manager.py</code> file will be generated within the <code>infra/services</code> directory, enriching the existing service structure.</p> <pre><code>infra\n\u251c\u2500\u2500 services\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 api_gateway.py\n    \u251c\u2500\u2500 aws_lambda.py\n    \u2514\u2500\u2500 secrets_manager.py\n</code></pre> <p>Additionally, the Services class found in <code>infra/services/__init__.py</code> will be automatically updated to include an instance of the newly created <code>SecretsManager</code> class, facilitating seamless integration and usage of Secrets Manager in your Lambda functions.</p> infra/services/__init__.py<pre><code>from infra.services.secrets_manager import SecretsManager\nfrom infra.services.api_gateway import APIGateway\nfrom infra.services.aws_lambda import AWSLambda\n\n\nclass Services:\n    def __init__(self, scope, context) -&gt; None:\n        self.api_gateway = APIGateway(scope, context)\n        self.aws_lambda = AWSLambda(scope, context)\n        self.secrets_manager = SecretsManager(scope, context.resources)\n</code></pre> <p>This is what the recently introduced SecretsManager class looks like:</p> infra/services/secrets_manager.py<pre><code>from aws_cdk import aws_secretsmanager as secrets_manager\n\n\nclass SecretsManager:\n    def __init__(self, scope, resources) -&gt; None:\n\n        self.secrets_manager = secrets_manager.Secret.from_secret_complete_arn(\n            scope,\n            id=\"SecretsManager\",\n            secret_complete_arn=resources[\"arns\"][\"secrets_manager_arn\"],\n        )\n</code></pre> <p>To streamline access to the Behind The Name API within our application, let's update our class variable to make use of the respective secret stored on Secrets Manager.</p> infra/services/secrets_manager.py<pre><code>from aws_cdk import aws_secretsmanager as secrets_manager\n\n\nclass SecretsManager:\n    def __init__(self, scope, resources) -&gt; None:\n\n        self.behind_the_name_secret = secrets_manager.Secret.from_secret_complete_arn(\n            scope,\n            id=\"BehindTheNameSecret\",\n            secret_complete_arn=\"$SECRET-ARN\",\n        )\n</code></pre> <p>Given that our application's three stages will utilize the same Secrets Manager resource, we can directly integrate the Behind The Name API secret ARN within the SecretsManager class itself.</p>"},{"location":"page5/#setting-up-dynamodb-tables-for-different-stages","title":"Setting Up DynamoDB Tables for Different Stages","text":"<p>Initiate the creation of three distinct DynamoDB tables, each designated for a specific deployment stage:</p> <ul> <li>Dev-Names</li> <li>Staging-Names</li> <li>Prod-Names</li> </ul> <p>In this tutorial we are going to use <code>PK</code> as Partition Key on our tables.</p> <p>With the ARNs for each table corresponding to the different stages now in hand, it's time to incorporate them into the <code>cdk.json</code> file.</p> cdk.json<pre><code>    \"dev\": {\n      \"arns\": {\n        \"names_table\": \"$DEV-NAMES-TABLE-ARN\"\n      }\n    },\n    \"staging\": {\n      \"arns\": {\n        \"names_table\": \"$STAGING-NAMES-TABLE-ARN\"\n      }\n    },\n    \"prod\": {\n      \"arns\": {\n        \"names_table\": \"$PROD-NAMES-TABLE-ARN\"\n      }\n    }\n</code></pre>"},{"location":"page5/#integrating-dynamodb-service","title":"Integrating DynamoDB Service","text":"<p>Just as we incorporated the Secrets Manager, the next step involves adding the DynamoDB service to our Service class for seamless interaction with DynamoDB tables. Execute the command below:</p> <p><code>forge service dynamo_db</code></p> <p>This action generates a new service file, <code>dynamo_db.py</code>, located in the <code>infra/services</code> directory, further expanding our suite of AWS services:</p> <pre><code>infra\n\u251c\u2500\u2500 services\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 api_gateway.py\n    \u251c\u2500\u2500 aws_lambda.py\n    \u251c\u2500\u2500 dynamo_db.py\n    \u2514\u2500\u2500 secrets_manager.p\n</code></pre> <p>Here's the revised edition of our Service class reflecting the latest updates:</p> infra/services/__init__.py<pre><code>from infra.services.dynamo_db import DynamoDB\nfrom infra.services.secrets_manager import SecretsManager\nfrom infra.services.api_gateway import APIGateway\nfrom infra.services.aws_lambda import AWSLambda\n\n\nclass Services:\n    def __init__(self, scope, context) -&gt; None:\n        self.api_gateway = APIGateway(scope, context)\n        self.aws_lambda = AWSLambda(scope, context)\n        self.secrets_manager = SecretsManager(scope, context.resources)\n        self.dynamo_db = DynamoDB(scope, context.resources)\n</code></pre> <p>This is the new DynamoDB class recently created.</p> infra/services/dynamo_db.py<pre><code>from aws_cdk import aws_dynamodb as dynamo_db\nfrom aws_cdk import aws_iam as iam\n\n\nclass DynamoDB:\n    def __init__(self, scope, resources: dict) -&gt; None:\n\n        self.dynamo = dynamo_db.Table.from_table_arn(\n            scope,\n            \"Dynamo\",\n            resources[\"arns\"][\"dynamo_arn\"],\n        )\n\n    @staticmethod\n    def add_query_permission(function, table):\n        function.add_to_role_policy(\n            iam.PolicyStatement(\n                actions=[\"dynamodb:Query\"],\n                resources=[f\"{table.table_arn}/index/*\"],\n            )\n        )\n</code></pre> <p>In DynamoDB development, querying data is a fundamental operation. Notably, the DynamoDB class is equipped with a helper method designed to simplify the process of granting query permissions. However, considering that our current project does not require querying capabilities, let's just remove this method. Furthermore, we should refine the class variables to directly reference our Names table.</p> infra/services/dynamo_db.py<pre><code>from aws_cdk import aws_dynamodb as dynamo_db\n\n\nclass DynamoDB:\n    def __init__(self, scope, resources: dict) -&gt; None:\n\n        self.names_table = dynamo_db.Table.from_table_arn(\n            scope,\n            \"NamesTable\",\n            resources[\"arns\"][\"names_table\"],\n        )\n</code></pre> <p>Ensure that the resource ARN precisely matches the name specified in your <code>cdk.json</code> file.</p>"},{"location":"page5/#creating-the-requests-layer","title":"Creating The Requests Layer","text":"<p>A crucial requirement for our application is to make HTTP requests to the Behind The Name API, which necessitates the use of the requests library. As this library isn't included in the standard Python environment for AWS Lambda, we need to incorporate it through a custom Lambda layer.</p> <p>Similarly to the other services, let's create it with Forge.</p> <p><code>forge service layers</code></p> <p>As expected, the layers are already added to the Service class.</p> infra/services/__init__.py<pre><code>from infra.services.layers import Layers\nfrom infra.services.dynamo_db import DynamoDB\nfrom infra.services.secrets_manager import SecretsManager\nfrom infra.services.api_gateway import APIGateway\nfrom infra.services.aws_lambda import AWSLambda\n\n\nclass Services:\n    def __init__(self, scope, context) -&gt; None:\n        self.api_gateway = APIGateway(scope, context)\n        self.aws_lambda = AWSLambda(scope, context)\n        self.secrets_manager = SecretsManager(scope, context.resources)\n        self.dynamo_db = DynamoDB(scope, context.resources)\n        self.layers = Layers(scope)\n</code></pre> <p>The requests library, due to its popularity, is available as a public layer for AWS Lambda, making it easier to include in your projects without creating a custom layer.</p> <p>We'll utilize a specific ARN for the requests library provided by Klayers for Python 3.9. You can find a list of public layers here. .</p> <p><code>arn:aws:lambda:us-east-2:770693421928:layer:Klayers-p39-requests:19</code>.</p> <p>Let's add the <code>requests</code> layer to our Layers class.</p> infra/services/layers.py<pre><code>from aws_cdk import aws_lambda as _lambda\n\n\nclass Layers:\n    def __init__(self, scope) -&gt; None:\n\n        self.requests_layer = _lambda.LayerVersion.from_layer_version_arn(\n            scope,\n            id=\"RequestsLayer\",\n            layer_version_arn=\"arn:aws:lambda:us-east-2:770693421928:layer:Klayers-p39-requests:19\",\n        )\n</code></pre> <p>With all services in place, it's time to create our Lambda functions.</p>"},{"location":"page5/#developing-the-create-function","title":"Developing the Create Function","text":"<p>Now we'll develop the \"Create\" component of our CRUD application, focusing on adding names and their nicknames to our DynamoDB tables. Execute the following Forge CLI command to create a Lambda function designed for this task:</p> <pre><code>forge function create_name --method \"POST\" --description \"Create a name and its respective nicknames on Dynamo DB\" --belongs names --public\n</code></pre> <p>The command instructs Forge to establish a new Lambda function, <code>create_name</code>, aimed at processing POST requests. Utilizing the <code>--belongs</code> flag, Forge is directed to categorize this function within the <code>names</code> folder, highlighting its connection to a group of related functions.</p> <pre><code>functions\n\u251c\u2500\u2500 names\n\u251c\u2500\u2500 create_name\n\u2502 \u251c\u2500\u2500 **init**.py\n\u2502 \u251c\u2500\u2500 config.py\n\u2502 \u251c\u2500\u2500 integration.py\n\u2502 \u251c\u2500\u2500 main.py\n\u2502 \u2514\u2500\u2500 unit.py\n\u2514\u2500\u2500 utils\n\u2514\u2500\u2500 **init**.py\n</code></pre> <ul> <li><code>names/</code> This directory acts as the container for all Lambda functions related to name operations, organizing them under a common theme.</li> <li><code>create_name/</code> This subdirectory is dedicated to the function for creating names, equipped with all necessary files for its execution, configuration, and testing.</li> <li><code>utils/</code> A utility directory for shared functions or helpers that support the operations within the names functions, enhancing code reuse and maintainability.</li> </ul>"},{"location":"page5/#enhanced-overview-of-create-name-endpoint","title":"Enhanced Overview of Create Name Endpoint","text":"<p>The Create Name endpoint is designed to enrich the data around a given name by fetching its associated nicknames from the \"Behind the Name\" API. It further consolidates this information by storing the original name along with its nicknames in a DynamoDB table, each entry uniquely identified by a UUID. This process not only aggregates relevant data for future retrieval but also standardizes name-related insights within the database.</p> <p>Now, let's delve into the details of the function implementation.</p> functions/names/create_name/main.py<pre><code>import json\nfrom dataclasses import dataclass\nimport json\nimport uuid\nimport os\nimport boto3\nimport requests\n\n@dataclass\nclass Input:\n    name: str\n\n\n@dataclass\nclass Output:\n    name_id: str\n\n\ndef lambda_handler(event, context):\n    dynamodb = boto3.resource(\"dynamodb\")\n    NAMES_TABLE_NAME = os.environ.get(\"NAMES_TABLE_NAME\")\n    names_table = dynamodb.Table(NAMES_TABLE_NAME)\n\n    secrets_manager = boto3.client(\"secretsmanager\")\n    BEHIND_THE_NAME_SECRET_NAME = os.environ.get(\"BEHIND_THE_NAME_SECRET_NAME\")\n    BEHIND_THE_NAME_API_KEY = secrets_manager.get_secret_value(SecretId=BEHIND_THE_NAME_SECRET_NAME)[\"SecretString\"]\n\n    body = json.loads(event[\"body\"])\n    name = body[\"name\"]\n\n    url = f\"https://www.behindthename.com/api/related.json?name={name}&amp;key={BEHIND_THE_NAME_API_KEY}\"\n    response = requests.get(url)\n\n    if \"error_code\" in response.text:\n        return {\"statusCode\": 500, \"body\": json.dumps({\"message\": response.text})}\n\n    name_id = str(uuid.uuid4())\n    nicknames = response.json()[\"names\"]\n    names_table.put_item(Item={\"PK\": name_id, \"name\": name, \"nicknames\": nicknames})\n\n    return {\"statusCode\": 200, \"body\": json.dumps({\"name_id\": name_id})}\n</code></pre> <p>This function interacts both with the <code>Behind the Name</code> API and an <code>AWS DynamoDB table</code>. It begins by extracting a name from the incoming event's body, then uses this name to query the API for related nicknames. If the API call is successful, it generates a unique identifier (UUID) for this name, and stores the name along with its nicknames in a DynamoDB table.</p> <p>Let's develop a configuration class to streamline the lambda function's access to necessary resources. This class will centralize the management of environment variables and resource configurations, thereby enhancing code maintainability and readability. It ensures that all external resources such as DynamoDB tables and API keys are easily configurable and securely accessed within the lambda function.</p> functions/names/create_name/config.py<pre><code>from infra.services import Services\n\n\nclass CreateNameConfig:\n    def __init__(self, services: Services) -&gt; None:\n\n        function = services.aws_lambda.create_function(\n            name=\"CreateName\",\n            path=\"./functions/names\",\n            description=\"Create a name and its respective nicknames on Dynamo DB\",\n            directory=\"create_name\",\n            layers=[services.layers.requests_layer],\n            environment={\n                \"NAMES_TABLE_NAME\": services.dynamo_db.names_table.table_name,\n                \"BEHIND_THE_NAME_SECRET_NAME\": services.secrets_manager.behind_the_name_secret.secret_name,\n            }\n        )\n\n        services.api_gateway.create_endpoint(\"POST\", \"/names\", function, public=True)\n\n        services.dynamo_db.names_table.grant_write_data(function)\n        services.secrets_manager.behind_the_name_secret.grant_read(function)\n</code></pre> <p>Overall, the <code>CreateNameConfig</code> class meticulously prepares the lambda function with the necessary tools and permissions for secure and efficient operation.</p> <p>This tutorial is dedicated to explain the architecture and operational intricacies of the Lambda Forge framework. In our quest for clarity and conciseness, we purposefully sidestep unit and integration testing discussions to avert inundating readers with too much detail. However, rest assured, the comprehensive project code, inclusive of approaches for mocking AWS resources in unit tests, will be hosted on GitHub. This deliberate choice ensures that enthusiasts desiring to dive into testing techniques can do so on their terms, fostering a learning environment that is both focused and comprehensive.</p>"}]}